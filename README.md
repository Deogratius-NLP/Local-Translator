ğŸ“ README Template: Local Language Translator

ğŸŒŸ Project Title: local Language Translator

utilizing machine learning models to provide real-time translations for the Haya, Sukuma, and Nyakyusa languages of Tanzania.

ğŸ¯ Overview

This project addresses the need for digital translation tools for under-resourced local languages in Tanzania. It provides a simple, interactive interface where a user can input a word or phrase in English and receive the corresponding (or closest equivalent) translation in Haya, Sukuma, and/or Nyakyusa.

The current demonstrator focuses on translating English words/phrases into Haya and Sukuma.

âœ¨ Features

    Bilingual Translation: Real-time translation from English to Haya and Sukuma.

    Multimodal Input: Supports translation from both typed text input and speech input (as demonstrated in the video).

    Intuitive Interface: A simple and clean user experience focused on speed and accuracy.

    Locally Sourced Data: Built on a proprietary dataset collected directly from native speakers of Haya, Sukuma, and Nyakyusa.

ğŸ’» Demo and Usage

See a live demonstration of the translator in action:

    [Video Demonstration Link]

        Link: https://drive.google.com/file/d/1k2Q_FGnTMxICxfAsIaRpCnMrVDlhUEFv/view?usp=sharing

        Description: The video shows a user typing/speaking an English word (e.g., "hello") and the application instantly displaying its corresponding translation in Haya and Sukuma.

ğŸ› ï¸ Technology Stack

The core components of this project are:

    [Programming Language, Python]

    [Key Framework/Library for ML, spaCy]

    [Specific Model Architecture, Sequence-to-Sequence (Seq2Seq) with Attention]

    [Interface/Frontend Technology, React]

    [ Speech Recognition/NLP Tools used Google Speech Recognition]

ğŸ’¾ Dataset Information

The performance of this translator is based on a unique and valuable corpus:

    Languages Covered: Haya, Sukuma, and Nyakyusa (with the current model outputting Haya and Sukuma).

    Data Source: Textual data collected and curated directly from native speakers and resources within the respective language communities.

    Current Status: The dataset used to train this model is proprietary and not yet publicly shared.

    Future Plans: We plan to release a sanitized and documented version of the dataset in the future to encourage further research into these languages.
